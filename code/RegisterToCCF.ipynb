{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b329b516",
   "metadata": {},
   "source": [
    "# Demo: Register SmartSPIM Data To CCF v3.1 Mouse Brain Atlas\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates a reproducible registration pipeline to align downsampled SmartSPIM data to the Allen Mouse Brain Common Coordinate Framework (CCF)$^1$. The notebook can be run interactively in CodeOcean to evaluate intermediate results or can be run from start to end for reproducible results in the CodeOcean capsule$^2$.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "1. Target (fixed) image. The CCF v3.1 atlas with updated spacing and spatial orientation is available in NIFTI format at http://download.alleninstitute.org/informatics-archive/converted_mouse_ccf/average_template/. More information on the CCF atlas is available at http://help.brain-map.org/display/mouseconnectivity/API\n",
    "\n",
    "2. Source (moving) image. Stitched SmartSPIM mouse brain images are available on the AWS S3 \"aind-open-data\" bucket in Zarr format. The largest resolution / smallest image size is used here for performance considerations.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "1. Registered source (moving) image aligned to CCF atlas space.\n",
    "\n",
    "2. ITK multistage composite transform mapping from source to target space.\n",
    "\n",
    "## Assumptions\n",
    "\n",
    "1. The source and target images are spatially oriented to common anatomical directions. This can be confirmed with a 3D spatial viewer such as 3D Slicer, ITKWidgets, or Neuroglancer. Note that viewers displaying voxel data without spatial information such as matplotlib may produce misleading visuals showing data aligned to different anatomical axes.\n",
    "\n",
    "2. The source image contains correct metadata. In this notebook the Zarr input sample is updated with known spatial metadata.\n",
    "\n",
    "## Procedure\n",
    "\n",
    "1. Data is read in from their respective stores attached via CodeOcean's data attachment mechanism.\n",
    "\n",
    "2. An initial translation is constructed to coarsely superimpose the source image on the target image. The source image is updated in place without resampling.\n",
    "\n",
    "3. The source image is registered to the target image. ITKElastix is used to optimize three transform stages for rigid, affine, and then deformable registration.\n",
    "\n",
    "4. Results are written out.\n",
    "\n",
    "## References\n",
    "\n",
    "1. Quanxin Wang, Song-Lin Ding, Yang Li, Josh Royall, David Feng, Phil Lesnar, Nile Graddis, Maitham Naeemi, Benjamin Facer, Anh Ho, Tim Dolbeare, Brandon Blanchard, Nick Dee, Wayne Wakeman, Karla E. Hirokawa, Aaron Szafer, Susan M. Sunkin, Seung Wook Oh, Amy Bernard, John W. Phillips, Michael Hawrylycz, Christof Koch, Hongkui Zeng, Julie A. Harris, Lydia Ng,\n",
    "The Allen Mouse Brain Common Coordinate Framework: A 3D Reference Atlas, Cell, Volume 181, Issue 4, 2020, Pages 936-953.e20, ISSN 0092-8674, https://doi.org/10.1016/j.cell.2020.04.007\n",
    "\n",
    "2. https://help.codeocean.com/en/articles/1111013-rendering-jupyter-notebooks-to-html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3375c518",
   "metadata": {},
   "source": [
    "## Initialize Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d8f66d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "import itk\n",
    "import numpy as np\n",
    "import ome_zarr\n",
    "from ome_zarr.reader import Reader as OMEZarrReader\n",
    "from ome_zarr.io import ZarrLocation\n",
    "import ome_zarr.utils\n",
    "\n",
    "assert \"ElastixRegistrationMethod\" in dir(itk)  # Ensure itk-elastix is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8fdf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registration results will be written to ../results/631680_Ex_647_Em_690\n"
     ]
    }
   ],
   "source": [
    "SOURCE_IMAGE_INPUT_FILEPATH = \"../data/SmartSPIM_631680_2022-09-09_13-52-33_stitched_2022-11-10_17-18-18/processed/OMEZarr/Ex_647_Em_690.zarr\"\n",
    "SAMPLE_ID = int(SOURCE_IMAGE_INPUT_FILEPATH.split(\"_\")[1])\n",
    "SAMPLE_CHANNEL = SOURCE_IMAGE_INPUT_FILEPATH.split(\"/\")[-1].split(\".zarr\")[0]\n",
    "SAMPLE_LEVEL = (\n",
    "    4  # data is scaled down by 2 ^ N in each direction or by 2 ^ 3N in total volume\n",
    ")\n",
    "SAMPLE_NAME = f\"{SAMPLE_ID}_{SAMPLE_CHANNEL}\"\n",
    "\n",
    "# Also available at http://download.alleninstitute.org/informatics-archive/converted_mouse_ccf/average_template/\n",
    "TARGET_IMAGE_INPUT_FILEPATH = (\n",
    "    \"../data/allen_mouse_ccf/average_template/average_template_25.nii.gz\"\n",
    ")\n",
    "\n",
    "REGISTERED_IMAGE_OUTPUT_PATH = f\"../results/{SAMPLE_NAME}\"\n",
    "REGISTERED_IMAGE_OUTPUT_FILENAME = f\"{SAMPLE_NAME}_registered.nii.gz\"\n",
    "\n",
    "print(f\"Registration results will be written to {REGISTERED_IMAGE_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330d7ef9",
   "metadata": {},
   "source": [
    "## Load SmartSPIM Source Image From Attached S3 Bucket\n",
    "\n",
    "SmartSPIM images are publicly available from the `aind-open-data` AWS S3 bucket and are mounted in the CodeOcean capsule in the `data` folder. The Allen Institute for Neural Dynamics has stitched the original SmartSPIM TIFF images into multiscale 3D volumes in OME-Zarr format. Additional metadata concerning data collection is made available in the `acquisition.json` file in the corresponding unstitched data folder for a given sample.\n",
    "\n",
    "We execute three key steps to fetch and initialize SmartSPIM data:\n",
    "\n",
    "1. Set up the OME-Zarr reader and fetch voxel data from the AWS S3 bucket. For registration demonstration we fetch the most downsampled multiscale level, which is the fourth level here. Each level represents downsampling by 2x in each image direction, so the fourth level is $2^{-4} = \\frac{1}{16}$ the resolution of the original stitched SmartSPIM image or $2^{3 * -4} = \\frac{1}{4096}$ the volume of the original SmartSPIM image.\n",
    "\n",
    "2. Parse OME-Zarr metadata to get the scaling along each voxel image direction. Note that the interface for Zarr and ITK voxel images is reversed such that the 0th index in a Zarr image represents the slowest-moving image direction (KJI) whereas the 0th index in an ITK image represents the fastest-moving image direction (IJK). Spacing is updated accordingly.\n",
    "\n",
    "3. Update the SmartSPIM ITK image to represent the anatomical directions of the collection space. ITK assumes that an image with identity direction aligns to \"right-to-left\", \"anterior-to-posterior\", \"inferior-to-superior\" (LPS) axes in that order. `acquisition.json` contains axis metadata specifying collection axis directions. The sample used in this notebook is collected in \"left-to-right\", \"posterior-to-anterior\", \"superior-to-inferior\" (RAI) space. We update the SmartSPIM ITK image to account for the different in anatomical space conventions, which results in the initial ITK image being spatially oriented to align with the CCF average template.\n",
    "\n",
    "#### Orientation Before Accounting for Anatomical Space Conventions\n",
    "\n",
    "![smartspim-before-reorient-2.png](files/images/smartspim-before-reorient.png)\n",
    "\n",
    "\n",
    "\n",
    "#### Orientation After Accounting for Anatomical Space Conventions\n",
    "\n",
    "![smartspim-after-reorient-2.png](files/images/smartspim-after-reorient.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1d0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(\n",
    "    SOURCE_IMAGE_INPUT_FILEPATH\n",
    "), \"Failed to get data! Did you attach the S3 bucket to this capsule?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af5892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/capsule/data/SmartSPIM_631680_2022-09-09_13-52-33_stitched_2022-11-10_17-18-18/processed/OMEZarr/Ex_647_Em_690.zarr [zgroup]\n",
      " - metadata\n",
      "   - Multiscales\n",
      "   - OMERO\n",
      " - data\n",
      "   - (1, 1, 4200, 10240, 7400)\n",
      "   - (1, 1, 2100, 5120, 3700)\n",
      "   - (1, 1, 1050, 2560, 1850)\n",
      "   - (1, 1, 525, 1280, 925)\n",
      "   - (1, 1, 262, 640, 462)\n"
     ]
    }
   ],
   "source": [
    "# Print information about multiscales available in the OME-Zarr sample\n",
    "_ = next(ome_zarr.utils.info(SOURCE_IMAGE_INPUT_FILEPATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "294ea1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/capsule/data/SmartSPIM_631680_2022-09-09_13-52-33_stitched_2022-11-10_17-18-18/processed/OMEZarr/Ex_647_Em_690.zarr [zgroup]\n"
     ]
    }
   ],
   "source": [
    "zarr_location = ZarrLocation(SOURCE_IMAGE_INPUT_FILEPATH)\n",
    "reader = OMEZarrReader(zarr_location)\n",
    "image_node = next(reader())\n",
    "print(image_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76bee291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0.028800000000000003, 'y': 0.028800000000000003, 'z': 0.032}\n"
     ]
    }
   ],
   "source": [
    "# Construct ITK spacing metadata from OME-Zarr metadata\n",
    "SPATIAL_AXES = (\"x\", \"y\", \"z\")\n",
    "zarr_spatial_axes = [\n",
    "    axis[\"name\"] for axis in image_node.metadata[\"axes\"] if axis[\"name\"] in SPATIAL_AXES\n",
    "]\n",
    "itk_spatial_axes = zarr_spatial_axes[::-1]\n",
    "\n",
    "ome_zarr_metadata = image_node.metadata\n",
    "\n",
    "axis_names = [axis[\"name\"] for axis in ome_zarr_metadata[\"axes\"]]\n",
    "axis_metadata_indices = {\n",
    "    axis_name: axis_names.index(axis_name) for axis_name in itk_spatial_axes\n",
    "}\n",
    "axis_units = {\n",
    "    axis_name: next(\n",
    "        axis for axis in ome_zarr_metadata[\"axes\"] if axis[\"name\"] == axis_name\n",
    "    )[\"unit\"]\n",
    "    for axis_name in itk_spatial_axes\n",
    "}\n",
    "\n",
    "axis_spacings = {\n",
    "    axis_name: ome_zarr_metadata[\"coordinateTransformations\"][0][0][\"scale\"][axis_index]\n",
    "    * (2**SAMPLE_LEVEL)\n",
    "    for axis_name, axis_index in axis_metadata_indices.items()\n",
    "}\n",
    "\n",
    "# Convert to millimeter spacing\n",
    "for axis_name in axis_spacings:\n",
    "    if axis_units[axis_name] == \"millimeter\":\n",
    "        continue\n",
    "    elif axis_units[axis_name] == \"micrometer\":\n",
    "        axis_spacings[axis_name] *= 1e-3\n",
    "    else:\n",
    "        raise KeyError(f\"Unexpected axis unit {axis_units[axis_name]}\")\n",
    "\n",
    "print(axis_spacings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abba0223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 147.76 MiB </td>\n",
       "                        <td> 577.50 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (262, 640, 462) </td>\n",
       "                        <td> (1, 640, 462) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 262 chunks in 3 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> uint16 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"175\" height=\"198\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"38\" y2=\"28\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"38\" y2=\"148\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"121\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"122\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"124\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"16\" y2=\"126\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"127\" />\n",
       "  <line x1=\"19\" y1=\"9\" x2=\"19\" y2=\"129\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"130\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"22\" y2=\"132\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"133\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"25\" y2=\"135\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"136\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"138\" />\n",
       "  <line x1=\"29\" y1=\"19\" x2=\"29\" y2=\"139\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"31\" y2=\"141\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"142\" />\n",
       "  <line x1=\"34\" y1=\"24\" x2=\"34\" y2=\"144\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"145\" />\n",
       "  <line x1=\"37\" y1=\"27\" x2=\"37\" y2=\"147\" />\n",
       "  <line x1=\"38\" y1=\"28\" x2=\"38\" y2=\"148\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 38.89705882352941,28.897058823529413 38.89705882352941,148.89705882352942 10.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"96\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"98\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"99\" y2=\"2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"101\" y2=\"4\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"102\" y2=\"6\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"104\" y2=\"7\" />\n",
       "  <line x1=\"19\" y1=\"9\" x2=\"105\" y2=\"9\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"107\" y2=\"10\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"108\" y2=\"12\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"110\" y2=\"13\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"111\" y2=\"15\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"113\" y2=\"16\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"114\" y2=\"18\" />\n",
       "  <line x1=\"29\" y1=\"19\" x2=\"116\" y2=\"19\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"117\" y2=\"21\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"119\" y2=\"22\" />\n",
       "  <line x1=\"34\" y1=\"24\" x2=\"120\" y2=\"24\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"122\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"27\" x2=\"123\" y2=\"27\" />\n",
       "  <line x1=\"38\" y1=\"28\" x2=\"125\" y2=\"28\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"38\" y2=\"28\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"96\" y1=\"0\" x2=\"125\" y2=\"28\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 96.625,0.0 125.52205882352942,28.897058823529413 38.89705882352941,28.897058823529413\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"38\" y1=\"28\" x2=\"125\" y2=\"28\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"38\" y1=\"148\" x2=\"125\" y2=\"148\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"38\" y1=\"28\" x2=\"38\" y2=\"148\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"125\" y1=\"28\" x2=\"125\" y2=\"148\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"38.89705882352941,28.897058823529413 125.52205882352942,28.897058823529413 125.52205882352942,148.89705882352942 38.89705882352941,148.89705882352942\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"82.209559\" y=\"168.897059\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >462</text>\n",
       "  <text x=\"145.522059\" y=\"88.897059\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,145.522059,88.897059)\">640</text>\n",
       "  <text x=\"14.448529\" y=\"154.448529\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,14.448529,154.448529)\">262</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<getitem, shape=(262, 640, 462), dtype=uint16, chunksize=(1, 640, 462), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print voxel information\n",
    "smartspim_voxels = np.squeeze(image_node.data[SAMPLE_LEVEL])\n",
    "smartspim_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25c09dbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image (0x55e0755111a0)\n",
      "  RTTI typeinfo:   itk::Image<float, 3u>\n",
      "  Reference Count: 1\n",
      "  Modified Time: 16\n",
      "  Debug: Off\n",
      "  Object Name: \n",
      "  Observers: \n",
      "    none\n",
      "  Source: (none)\n",
      "  Source output name: (none)\n",
      "  Release Data: Off\n",
      "  Data Released: False\n",
      "  Global Release Data: Off\n",
      "  PipelineMTime: 0\n",
      "  UpdateMTime: 0\n",
      "  RealTimeStamp: 0 seconds \n",
      "  LargestPossibleRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [462, 640, 262]\n",
      "  BufferedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [462, 640, 262]\n",
      "  RequestedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [462, 640, 262]\n",
      "  Spacing: [0.0288, 0.0288, 0.032]\n",
      "  Origin: [0, 0, 0]\n",
      "  Direction: \n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "\n",
      "  IndexToPointMatrix: \n",
      "0.0288 0 0\n",
      "0 0.0288 0\n",
      "0 0 0.032\n",
      "\n",
      "  PointToIndexMatrix: \n",
      "34.7222 0 0\n",
      "0 34.7222 0\n",
      "0 0 31.25\n",
      "\n",
      "  Inverse Direction: \n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "\n",
      "  PixelContainer: \n",
      "    ImportImageContainer (0x55e075476270)\n",
      "      RTTI typeinfo:   itk::ImportImageContainer<unsigned long, float>\n",
      "      Reference Count: 1\n",
      "      Modified Time: 14\n",
      "      Debug: Off\n",
      "      Object Name: \n",
      "      Observers: \n",
      "        none\n",
      "      Pointer: 0x7f2e530f6010\n",
      "      Container manages memory: true\n",
      "      Size: 77468160\n",
      "      Capacity: 77468160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_image = itk.image_from_array(smartspim_voxels.astype(np.float32))\n",
    "source_image.SetSpacing([axis_spacings[axis_name] for axis_name in itk_spatial_axes])\n",
    "print(source_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9b7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image orientation is derived from accompanying \"acquisition.json\" file\n",
    "\n",
    "# ITK is in \"right-to-left\", \"anterior-to-posterior\", \"inferior-to-superior\" (LPS) space.\n",
    "# \"acquisition.json\" for \"SmartSPIM_631680_2022-09-09_13-52-33\" shows voxel data uses same\n",
    "# axes order but inverted, i.e. \"left-to-right\", \"posterior-to-anterior\", \"superior-to-inferior\" (RAI).\n",
    "\n",
    "INPUT_COORDINATE_ORIENTATION = (\n",
    "    itk.SpatialOrientationEnums.ValidCoordinateOrientations_ITK_COORDINATE_ORIENTATION_RAI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1fd2a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image (0x55e0755111a0)\n",
      "  RTTI typeinfo:   itk::Image<float, 3u>\n",
      "  Reference Count: 2\n",
      "  Modified Time: 103\n",
      "  Debug: Off\n",
      "  Object Name: \n",
      "  Observers: \n",
      "    none\n",
      "  Source: (none)\n",
      "  Source output name: (none)\n",
      "  Release Data: Off\n",
      "  Data Released: False\n",
      "  Global Release Data: Off\n",
      "  PipelineMTime: 0\n",
      "  UpdateMTime: 0\n",
      "  RealTimeStamp: 0 seconds \n",
      "  LargestPossibleRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [462, 640, 262]\n",
      "  BufferedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [462, 640, 262]\n",
      "  RequestedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [462, 640, 262]\n",
      "  Spacing: [0.0288, 0.0288, 0.032]\n",
      "  Origin: [13.2768, 18.4032, 8.352]\n",
      "  Direction: \n",
      "-1 0 0\n",
      "0 -1 0\n",
      "0 0 -1\n",
      "\n",
      "  IndexToPointMatrix: \n",
      "-0.0288 0 0\n",
      "0 -0.0288 0\n",
      "0 0 -0.032\n",
      "\n",
      "  PointToIndexMatrix: \n",
      "-34.7222 0 0\n",
      "0 -34.7222 0\n",
      "0 0 -31.25\n",
      "\n",
      "  Inverse Direction: \n",
      "-1 0 0\n",
      "0 -1 0\n",
      "0 0 -1\n",
      "\n",
      "  PixelContainer: \n",
      "    ImportImageContainer (0x55e075476270)\n",
      "      RTTI typeinfo:   itk::ImportImageContainer<unsigned long, float>\n",
      "      Reference Count: 1\n",
      "      Modified Time: 14\n",
      "      Debug: Off\n",
      "      Object Name: \n",
      "      Observers: \n",
      "        none\n",
      "      Pointer: 0x7f2e530f6010\n",
      "      Container manages memory: true\n",
      "      Size: 77468160\n",
      "      Capacity: 77468160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orient_filter = itk.OrientImageFilter[type(source_image), type(source_image)].New()\n",
    "orient_filter.SetInput(source_image)\n",
    "orient_filter.SetGivenCoordinateOrientation(INPUT_COORDINATE_ORIENTATION)\n",
    "orient_filter.SetDesiredCoordinateOrientation(\n",
    "    itk.SpatialOrientationEnums.ValidCoordinateOrientations_ITK_COORDINATE_ORIENTATION_LPS\n",
    ")\n",
    "orient_filter.UpdateOutputInformation()\n",
    "\n",
    "source_image.CopyInformation(orient_filter.GetOutput())\n",
    "print(source_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40303fba",
   "metadata": {},
   "source": [
    "## Load CCF Atlas Target Image from CodeOcean Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "349c8075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image (0x55e076648b80)\n",
      "  RTTI typeinfo:   itk::Image<float, 3u>\n",
      "  Reference Count: 1\n",
      "  Modified Time: 519\n",
      "  Debug: Off\n",
      "  Object Name: \n",
      "  Observers: \n",
      "    none\n",
      "  Source: (none)\n",
      "  Source output name: (none)\n",
      "  Release Data: Off\n",
      "  Data Released: False\n",
      "  Global Release Data: Off\n",
      "  PipelineMTime: 334\n",
      "  UpdateMTime: 518\n",
      "  RealTimeStamp: 0 seconds \n",
      "  LargestPossibleRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [528, 320, 456]\n",
      "  BufferedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [528, 320, 456]\n",
      "  RequestedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [528, 320, 456]\n",
      "  Spacing: [0.025, 0.025, 0.025]\n",
      "  Origin: [0, 0, 0]\n",
      "  Direction: \n",
      "-0 0 -1\n",
      "1 -0 0\n",
      "0 -1 0\n",
      "\n",
      "  IndexToPointMatrix: \n",
      "0 0 -0.025\n",
      "0.025 0 0\n",
      "0 -0.025 0\n",
      "\n",
      "  PointToIndexMatrix: \n",
      "0 40 0\n",
      "0 0 -40\n",
      "-40 0 0\n",
      "\n",
      "  Inverse Direction: \n",
      "0 1 0\n",
      "0 0 -1\n",
      "-1 0 0\n",
      "\n",
      "  PixelContainer: \n",
      "    ImportImageContainer (0x55e076c1a320)\n",
      "      RTTI typeinfo:   itk::ImportImageContainer<unsigned long, float>\n",
      "      Reference Count: 1\n",
      "      Modified Time: 515\n",
      "      Debug: Off\n",
      "      Object Name: \n",
      "      Observers: \n",
      "        none\n",
      "      Pointer: 0x7f2e68614010\n",
      "      Container manages memory: true\n",
      "      Size: 77045760\n",
      "      Capacity: 77045760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_image = itk.imread(TARGET_IMAGE_INPUT_FILEPATH, pixel_type=itk.F)\n",
    "\n",
    "# Note: 3.1 template is in mm (3.0 was um)\n",
    "print(target_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b87f9",
   "metadata": {},
   "source": [
    "## Validate Data\n",
    "\n",
    "We briefly evaluate the source and target images to ensure that image physical sizes are on the same order of magnitude as expected. A significant difference in image sizes could indicate a problem with image spacing.\n",
    "\n",
    "A 3D spatial viewer such as ITKWidgets or Neuroglancer can be used to evaluate that source and target input images share a spatial orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d84ff8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCF physical bounds: [11.40000017 13.2000002   8.00000012]\n",
      "SmartSPIM physical bounds: [13.3056 18.432   8.384 ]\n"
     ]
    }
   ],
   "source": [
    "def get_bounds(image, transform=None):\n",
    "    image_bounds = [\n",
    "        itk.origin(image),\n",
    "        image.TransformIndexToPhysicalPoint(itk.size(image)),\n",
    "    ]\n",
    "    return (\n",
    "        [transform.TransformPoint(pt) for pt in image_bounds]\n",
    "        if transform\n",
    "        else image_bounds\n",
    "    )\n",
    "\n",
    "\n",
    "def get_physical_size(image, transform=None):\n",
    "    bounds = get_bounds(image, transform)\n",
    "    return np.absolute(np.array(bounds[1]) - np.array(bounds[0]))\n",
    "\n",
    "\n",
    "def print_bounds(image, transform=None):\n",
    "    image_bounds = get_bounds(image, transform)\n",
    "    print(f\"{image_bounds[0]}, {image_bounds[1]}\")\n",
    "\n",
    "\n",
    "print(f\"CCF physical bounds: {get_physical_size(target_image)}\")\n",
    "print(f\"SmartSPIM physical bounds: {get_physical_size(source_image)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b07945",
   "metadata": {},
   "source": [
    "## Initialize Registration with `itk`\n",
    "\n",
    "We use tools available in the Insight Toolkit to align the source and target images so that they are initially overlapping in space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc7223d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2000D\u001b[KLoading ITKMesh... \u001b[2000D\u001b[KLoading ITKMesh... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKSpatialObjects... \u001b[2000D\u001b[KLoading ITKSpatialObjects... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKImageSources... \u001b[2000D\u001b[KLoading ITKImageSources... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKFFT... \u001b[2000D\u001b[KLoading ITKFFT... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKImageCompose... \u001b[2000D\u001b[KLoading ITKImageCompose... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKImageStatistics... \u001b[2000D\u001b[KLoading ITKImageStatistics... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKPath... \u001b[2000D\u001b[KLoading ITKPath... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKImageIntensity... \u001b[2000D\u001b[KLoading ITKImageIntensity... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKThresholding... \u001b[2000D\u001b[KLoading ITKThresholding... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKConvolution... \u001b[2000D\u001b[KLoading ITKConvolution... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKSmoothing... \u001b[2000D\u001b[KLoading ITKSmoothing... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKOptimizers... \u001b[2000D\u001b[KLoading ITKOptimizers... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKImageGradient... \u001b[2000D\u001b[KLoading ITKImageGradient... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKImageFeature... \u001b[2000D\u001b[KLoading ITKImageFeature... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKFiniteDifference... \u001b[2000D\u001b[KLoading ITKFiniteDifference... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKDisplacementField... \u001b[2000D\u001b[KLoading ITKDisplacementField... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKRegistrationCommon... \u001b[2000D\u001b[KLoading ITKRegistrationCommon... \u001b[2000D\u001b[K"
     ]
    }
   ],
   "source": [
    "itk.auto_progress(1)\n",
    "itk.CenteredTransformInitializer\n",
    "itk.auto_progress(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "025fa012",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixOffsetTransformBase (0x55e073ffa100)\n",
      "  RTTI typeinfo:   itk::MatrixOffsetTransformBase<double, 3u, 3u>\n",
      "  Reference Count: 1\n",
      "  Modified Time: 607\n",
      "  Debug: Off\n",
      "  Object Name: \n",
      "  Observers: \n",
      "    none\n",
      "  Matrix: \n",
      "    1 0 0 \n",
      "    0 1 0 \n",
      "    0 0 1 \n",
      "  Offset: [-12.3259, -2.6141, -8.1635]\n",
      "  Center: [-5.6875, 6.5875, -3.9875]\n",
      "  Translation: [-12.3259, -2.6141, -8.1635]\n",
      "  Inverse: \n",
      "    1 0 0 \n",
      "    0 1 0 \n",
      "    0 0 1 \n",
      "  Singular: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Translate to roughly position sample data on top of CCF data\n",
    "\n",
    "init_transform = itk.VersorRigid3DTransform[\n",
    "    itk.D\n",
    "].New()  # Represents 3D rigid transformation with unit quaternion\n",
    "init_transform.SetIdentity()\n",
    "\n",
    "transform_initializer = itk.CenteredVersorTransformInitializer[\n",
    "    type(target_image), type(source_image)\n",
    "].New()\n",
    "transform_initializer.SetFixedImage(target_image)\n",
    "transform_initializer.SetMovingImage(source_image)\n",
    "transform_initializer.SetTransform(init_transform)\n",
    "transform_initializer.GeometryOn()  # We compute translation between the center of each image\n",
    "transform_initializer.ComputeRotationOff()  # We have previously verified that spatial orientation aligns\n",
    "\n",
    "transform_initializer.InitializeTransform()\n",
    "\n",
    "# initializer maps from the fixed image to the moving image,\n",
    "# whereas we want to map from the moving image to the fixed image.\n",
    "init_transform = init_transform.GetInverseTransform()\n",
    "\n",
    "print(init_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c0097d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image (0x55e077c38f10)\n",
      "  RTTI typeinfo:   itk::Image<float, 3u>\n",
      "  Reference Count: 2\n",
      "  Modified Time: 629\n",
      "  Debug: Off\n",
      "  Object Name: \n",
      "  Observers: \n",
      "    none\n",
      "  Source: (0x55e07744ceb0) \n",
      "  Source output name: Primary\n",
      "  Release Data: Off\n",
      "  Data Released: False\n",
      "  Global Release Data: Off\n",
      "  PipelineMTime: 623\n",
      "  UpdateMTime: 0\n",
      "  RealTimeStamp: 0 seconds \n",
      "  LargestPossibleRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [462, 640, 262]\n",
      "  BufferedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [0, 0, 0]\n",
      "  RequestedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [0, 0, 0]\n",
      "  Spacing: [0.0288, 0.0288, 0.032]\n",
      "  Origin: [0.9509, 15.7891, 0.1885]\n",
      "  Direction: \n",
      "-1 0 0\n",
      "0 -1 0\n",
      "0 0 -1\n",
      "\n",
      "  IndexToPointMatrix: \n",
      "-0.0288 0 0\n",
      "0 -0.0288 0\n",
      "0 0 -0.032\n",
      "\n",
      "  PointToIndexMatrix: \n",
      "-34.7222 0 0\n",
      "0 -34.7222 0\n",
      "0 0 -31.25\n",
      "\n",
      "  Inverse Direction: \n",
      "-1 0 0\n",
      "0 -1 0\n",
      "0 0 -1\n",
      "\n",
      "  PixelContainer: \n",
      "    ImportImageContainer (0x55e077d84270)\n",
      "      RTTI typeinfo:   itk::ImportImageContainer<unsigned long, float>\n",
      "      Reference Count: 1\n",
      "      Modified Time: 612\n",
      "      Debug: Off\n",
      "      Object Name: \n",
      "      Observers: \n",
      "        none\n",
      "      Pointer: 0\n",
      "      Container manages memory: true\n",
      "      Size: 0\n",
      "      Capacity: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply translation without resampling the image by updating the image origin directly\n",
    "change_information_filter = itk.ChangeInformationImageFilter[type(source_image)].New()\n",
    "change_information_filter.SetInput(source_image)\n",
    "change_information_filter.SetOutputOrigin(\n",
    "    init_transform.TransformPoint(itk.origin(source_image))\n",
    ")\n",
    "change_information_filter.ChangeOriginOn()\n",
    "change_information_filter.UpdateOutputInformation()\n",
    "\n",
    "source_image_init = change_information_filter.GetOutput()\n",
    "print(source_image_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67296afe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original input source image bounds: itkPointD3 ([13.2768, 18.4032, 8.352]), itkPointD3 ([-0.0288, -0.0288, -0.032])\n",
      "Translated source image bounds: itkPointD3 ([0.9509, 15.7891, 0.1885]), itkPointD3 ([-12.3547, -2.6429, -8.1955])\n",
      "Target image bounds: itkPointD3 ([0, 0, 0]), itkPointD3 ([-11.4, 13.2, -8])\n"
     ]
    }
   ],
   "source": [
    "# Verify that the initialized source image bounds overlap with the target image\n",
    "\n",
    "print(\n",
    "    f\"Original input source image bounds: {get_bounds(source_image)[0]}, {get_bounds(source_image)[1]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Translated source image bounds: {get_bounds(source_image_init)[0]}, {get_bounds(source_image_init)[1]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Target image bounds: {get_bounds(target_image)[0]}, {get_bounds(target_image)[1]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eabb69",
   "metadata": {},
   "source": [
    "## Register with `itk-elastix`\n",
    "\n",
    "We use the tools developed in Elastix and made available via the ITKElastix Python module to perform multistage registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c673fd5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2000D\u001b[KLoading ITKVoronoi... \u001b[2000D\u001b[KLoading ITKVoronoi... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKQuadEdgeMesh... \u001b[2000D\u001b[KLoading ITKQuadEdgeMesh... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKIOMeshBase... \u001b[2000D\u001b[KLoading ITKIOMeshBYU... \u001b[2000D\u001b[KLoading ITKIOMeshBYU... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKIOMeshFreeSurfer... \u001b[2000D\u001b[KLoading ITKIOMeshFreeSurfer... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKIOMeshGifti... \u001b[2000D\u001b[KLoading ITKIOMeshGifti... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKIOMeshOBJ... \u001b[2000D\u001b[KLoading ITKIOMeshOBJ... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKIOMeshOFF... \u001b[2000D\u001b[KLoading ITKIOMeshOFF... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKIOMeshVTK... \u001b[2000D\u001b[KLoading ITKIOMeshVTK... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading ITKIOMeshBase... \u001b[2000D\u001b[K\u001b[2000D\u001b[KLoading Elastix... \u001b[2000D\u001b[KLoading Elastix... \u001b[2000D\u001b[K"
     ]
    }
   ],
   "source": [
    "itk.auto_progress(1)\n",
    "itk.ElastixRegistrationMethod\n",
    "itk.auto_progress(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0085db4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParameterObject (0x55e074f426e0)\n",
      "  RTTI typeinfo:   elastix::ParameterObject\n",
      "  Reference Count: 1\n",
      "  Modified Time: 67\n",
      "  Debug: Off\n",
      "  Object Name: \n",
      "  Observers: \n",
      "    none\n",
      "ParameterMap 0: \n",
      "  (AutomaticParameterEstimation \"true\")\n",
      "  (AutomaticScalesEstimation \"true\")\n",
      "  (CheckNumberOfSamples \"true\")\n",
      "  (DefaultPixelValue 0)\n",
      "  (FinalBSplineInterpolationOrder 3)\n",
      "  (FixedImagePyramid \"FixedSmoothingImagePyramid\")\n",
      "  (ImageSampler \"RandomCoordinate\")\n",
      "  (Interpolator \"LinearInterpolator\")\n",
      "  (MaximumNumberOfIterations 256)\n",
      "  (MaximumNumberOfSamplingAttempts 8)\n",
      "  (Metric \"AdvancedMattesMutualInformation\")\n",
      "  (MovingImagePyramid \"MovingSmoothingImagePyramid\")\n",
      "  (NewSamplesEveryIteration \"true\")\n",
      "  (NumberOfResolutions 4)\n",
      "  (NumberOfSamplesForExactGradient 4096)\n",
      "  (NumberOfSpatialSamples 2048)\n",
      "  (Optimizer \"AdaptiveStochasticGradientDescent\")\n",
      "  (Registration \"MultiResolutionRegistration\")\n",
      "  (ResampleInterpolator \"FinalBSplineInterpolator\")\n",
      "  (Resampler \"DefaultResampler\")\n",
      "  (ResultImageFormat \"nii\")\n",
      "  (Transform \"EulerTransform\")\n",
      "  (WriteIterationInfo \"false\")\n",
      "  (WriteResultImage \"true\")\n",
      "ParameterMap 1: \n",
      "  (AutomaticParameterEstimation \"true\")\n",
      "  (AutomaticScalesEstimation \"true\")\n",
      "  (CheckNumberOfSamples \"true\")\n",
      "  (DefaultPixelValue 0)\n",
      "  (FinalBSplineInterpolationOrder 3)\n",
      "  (FixedImagePyramid \"FixedSmoothingImagePyramid\")\n",
      "  (ImageSampler \"RandomCoordinate\")\n",
      "  (Interpolator \"LinearInterpolator\")\n",
      "  (MaximumNumberOfIterations 256)\n",
      "  (MaximumNumberOfSamplingAttempts 8)\n",
      "  (Metric \"AdvancedMattesMutualInformation\")\n",
      "  (MovingImagePyramid \"MovingSmoothingImagePyramid\")\n",
      "  (NewSamplesEveryIteration \"true\")\n",
      "  (NumberOfResolutions 4)\n",
      "  (NumberOfSamplesForExactGradient 4096)\n",
      "  (NumberOfSpatialSamples 2048)\n",
      "  (Optimizer \"AdaptiveStochasticGradientDescent\")\n",
      "  (Registration \"MultiResolutionRegistration\")\n",
      "  (ResampleInterpolator \"FinalBSplineInterpolator\")\n",
      "  (Resampler \"DefaultResampler\")\n",
      "  (ResultImageFormat \"nii\")\n",
      "  (Transform \"AffineTransform\")\n",
      "  (WriteIterationInfo \"false\")\n",
      "  (WriteResultImage \"true\")\n",
      "ParameterMap 2: \n",
      "  (AutomaticParameterEstimation \"true\")\n",
      "  (CheckNumberOfSamples \"true\")\n",
      "  (DefaultPixelValue 0)\n",
      "  (FinalBSplineInterpolationOrder 3)\n",
      "  (FinalGridSpacingInPhysicalUnits 0.5)\n",
      "  (FixedImagePyramid \"FixedSmoothingImagePyramid\")\n",
      "  (GridSpacingSchedule 2.80322 1.9881 1.41 1)\n",
      "  (ImageSampler \"RandomCoordinate\")\n",
      "  (Interpolator \"LinearInterpolator\")\n",
      "  (MaximumNumberOfIterations 256)\n",
      "  (MaximumNumberOfSamplingAttempts 8)\n",
      "  (Metric \"AdvancedMattesMutualInformation\" \"TransformBendingEnergyPenalty\")\n",
      "  (Metric0Weight 1)\n",
      "  (Metric1Weight 1)\n",
      "  (MovingImagePyramid \"MovingSmoothingImagePyramid\")\n",
      "  (NewSamplesEveryIteration \"true\")\n",
      "  (NumberOfResolutions 4)\n",
      "  (NumberOfSamplesForExactGradient 4096)\n",
      "  (NumberOfSpatialSamples 2048)\n",
      "  (Optimizer \"AdaptiveStochasticGradientDescent\")\n",
      "  (Registration \"MultiMetricMultiResolutionRegistration\")\n",
      "  (ResampleInterpolator \"FinalBSplineInterpolator\")\n",
      "  (Resampler \"DefaultResampler\")\n",
      "  (ResultImageFormat \"nii\")\n",
      "  (Transform \"BSplineTransform\")\n",
      "  (WriteIterationInfo \"false\")\n",
      "  (WriteResultImage \"true\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameter_object = itk.ParameterObject.New()\n",
    "parameter_object.AddParameterMap(\n",
    "    parameter_object.GetDefaultParameterMap(\"rigid\")\n",
    ")\n",
    "parameter_object.AddParameterMap(\n",
    "    parameter_object.GetDefaultParameterMap(\"affine\")\n",
    ")\n",
    "\n",
    "bspline_map = parameter_object.GetDefaultParameterMap(\"bspline\")\n",
    "bspline_map[\"FinalGridSpacingInPhysicalUnits\"] = (\"0.5000\",)\n",
    "parameter_object.AddParameterMap(bspline_map)\n",
    "\n",
    "print(parameter_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95e4506d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "registration_method = itk.ElastixRegistrationMethod[\n",
    "    type(target_image), type(source_image)\n",
    "].New(\n",
    "    fixed_image=target_image,\n",
    "    moving_image=source_image_init,\n",
    "    parameter_object=parameter_object,\n",
    "    log_to_console=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfa7a4f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run registration with `itk-elastix`, may take a few minutes\n",
    "registration_method.Update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a821b31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered source image bounds: itkPointD3 ([0, 0, 0]),itkPointD3 ([-11.4, 13.2, -8])\n",
      "Target image bounds: itkPointD3 ([0, 0, 0]), itkPointD3 ([-11.4, 13.2, -8])\n"
     ]
    }
   ],
   "source": [
    "# Verify that the registered source image bounds concide with the target image\n",
    "\n",
    "print(\n",
    "    f\"Registered source image bounds: {get_bounds(registration_method.GetOutput())[0]},\"\n",
    "    f\"{get_bounds(registration_method.GetOutput())[1]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Target image bounds: {get_bounds(target_image)[0]}, {get_bounds(target_image)[1]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f20220e",
   "metadata": {},
   "source": [
    "## Save Outputs To Disk\n",
    "\n",
    "Reproducible results should be saved to the capsule 'data' folder. Registration results from this notebook include:\n",
    "- The registered, resampled SmartSPIM image. This can be compared with the target CCF average template image or CCF label atlas in a spatial viewer for visual evaluation of registration fitness.\n",
    "- The sequence of transforms used to map from the source SmartSPIM sample space to target CCF space. We can map corresponding information in SmartSPIM source space such as segmentations or other markups into CCF space by applying this sequence of transformations.\n",
    "    - The ITK versor transform used to initialize the volumes for registration;\n",
    "    - The sequence of Elastix transforms generated by registration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "431621d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(REGISTERED_IMAGE_OUTPUT_PATH, exist_ok=True)\n",
    "itk.imwrite(\n",
    "    registration_method.GetOutput(),\n",
    "    f\"{REGISTERED_IMAGE_OUTPUT_PATH}/{REGISTERED_IMAGE_OUTPUT_FILENAME}\",\n",
    "    compression=True,\n",
    ")\n",
    "\n",
    "itk.transformwrite(\n",
    "    [init_transform], f\"{REGISTERED_IMAGE_OUTPUT_PATH}/init-transform.hdf5\"\n",
    ")\n",
    "for index in range(parameter_object.GetNumberOfParameterMaps()):\n",
    "    registration_method.GetTransformParameterObject().WriteParameterFile(\n",
    "        registration_method.GetTransformParameterObject().GetParameterMap(index),\n",
    "        f\"{REGISTERED_IMAGE_OUTPUT_PATH}/elastix-transform{index}.txt\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
